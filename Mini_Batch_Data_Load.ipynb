{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMn0NbztJYqlaN7NnWUdEPW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tlBB9EOvdnk1"
      },
      "outputs": [],
      "source": [
        "# 데이터를 작은 단위로 나누어 해당 단위로 학습\n",
        "# 각 단위에 대한 cost계산 => gradient descent\n",
        "# 데이터의 나누어진 모든 단위에 대한 학습 => 1 Epoch\n",
        "# Minibatch의 크기 => batch size\n",
        "# CPU, GPU의 메모리가 2의 배수 => Batch Size는 2의 제곱수"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "0Zr-nL9xeuW0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
        "from torch.utils.data import DataLoader # 데이터로더"
      ],
      "metadata": {
        "id": "OQvDjXK2eug5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train  =  torch.FloatTensor([[73,  80,  75],\n",
        "                               [93,  88,  93],\n",
        "                               [89,  91,  90],\n",
        "                               [96,  98,  100],\n",
        "                               [73,  66,  70]])\n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])"
      ],
      "metadata": {
        "id": "njXCwV60eujU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#입력과 출력을 합쳐서 tensor 생성\n",
        "dataset = TensorDataset(x_train, y_train)"
      ],
      "metadata": {
        "id": "j2Q3HSxceulo"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Batch_Size가 2가 되도록 data를 shuffle하여 batch 생성\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "xtX6biYSeun4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Linear(3,1)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "-sqCRGdVeuqQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    # print(batch_idx)\n",
        "    # print(samples)\n",
        "    x_train, y_train = samples\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "    # cost로 H(x) 계산\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
        "        cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2WqEszReusw",
        "outputId": "0f91b328-5ef3-4e76-ad75-cb97be9702bb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/20 Batch 1/3 Cost: 21982.144531\n",
            "Epoch    0/20 Batch 2/3 Cost: 7693.620117\n",
            "Epoch    0/20 Batch 3/3 Cost: 3825.247803\n",
            "Epoch    1/20 Batch 1/3 Cost: 399.175903\n",
            "Epoch    1/20 Batch 2/3 Cost: 299.441193\n",
            "Epoch    1/20 Batch 3/3 Cost: 72.529640\n",
            "Epoch    2/20 Batch 1/3 Cost: 18.912996\n",
            "Epoch    2/20 Batch 2/3 Cost: 1.684941\n",
            "Epoch    2/20 Batch 3/3 Cost: 12.109414\n",
            "Epoch    3/20 Batch 1/3 Cost: 4.925326\n",
            "Epoch    3/20 Batch 2/3 Cost: 1.301397\n",
            "Epoch    3/20 Batch 3/3 Cost: 7.404551\n",
            "Epoch    4/20 Batch 1/3 Cost: 4.833017\n",
            "Epoch    4/20 Batch 2/3 Cost: 2.485444\n",
            "Epoch    4/20 Batch 3/3 Cost: 4.219296\n",
            "Epoch    5/20 Batch 1/3 Cost: 1.568783\n",
            "Epoch    5/20 Batch 2/3 Cost: 9.107225\n",
            "Epoch    5/20 Batch 3/3 Cost: 4.022615\n",
            "Epoch    6/20 Batch 1/3 Cost: 1.529237\n",
            "Epoch    6/20 Batch 2/3 Cost: 9.164570\n",
            "Epoch    6/20 Batch 3/3 Cost: 3.986827\n",
            "Epoch    7/20 Batch 1/3 Cost: 4.192684\n",
            "Epoch    7/20 Batch 2/3 Cost: 4.940251\n",
            "Epoch    7/20 Batch 3/3 Cost: 0.224993\n",
            "Epoch    8/20 Batch 1/3 Cost: 2.609911\n",
            "Epoch    8/20 Batch 2/3 Cost: 5.301592\n",
            "Epoch    8/20 Batch 3/3 Cost: 5.533866\n",
            "Epoch    9/20 Batch 1/3 Cost: 4.185911\n",
            "Epoch    9/20 Batch 2/3 Cost: 4.825052\n",
            "Epoch    9/20 Batch 3/3 Cost: 0.975825\n",
            "Epoch   10/20 Batch 1/3 Cost: 4.813631\n",
            "Epoch   10/20 Batch 2/3 Cost: 1.402797\n",
            "Epoch   10/20 Batch 3/3 Cost: 7.222492\n",
            "Epoch   11/20 Batch 1/3 Cost: 3.206259\n",
            "Epoch   11/20 Batch 2/3 Cost: 9.273069\n",
            "Epoch   11/20 Batch 3/3 Cost: 0.205516\n",
            "Epoch   12/20 Batch 1/3 Cost: 3.153975\n",
            "Epoch   12/20 Batch 2/3 Cost: 4.454237\n",
            "Epoch   12/20 Batch 3/3 Cost: 7.927246\n",
            "Epoch   13/20 Batch 1/3 Cost: 3.568076\n",
            "Epoch   13/20 Batch 2/3 Cost: 4.019035\n",
            "Epoch   13/20 Batch 3/3 Cost: 5.567874\n",
            "Epoch   14/20 Batch 1/3 Cost: 4.365198\n",
            "Epoch   14/20 Batch 2/3 Cost: 4.495830\n",
            "Epoch   14/20 Batch 3/3 Cost: 5.825119\n",
            "Epoch   15/20 Batch 1/3 Cost: 4.376290\n",
            "Epoch   15/20 Batch 2/3 Cost: 4.959274\n",
            "Epoch   15/20 Batch 3/3 Cost: 5.006488\n",
            "Epoch   16/20 Batch 1/3 Cost: 1.714484\n",
            "Epoch   16/20 Batch 2/3 Cost: 7.511556\n",
            "Epoch   16/20 Batch 3/3 Cost: 5.565930\n",
            "Epoch   17/20 Batch 1/3 Cost: 0.360417\n",
            "Epoch   17/20 Batch 2/3 Cost: 5.378123\n",
            "Epoch   17/20 Batch 3/3 Cost: 7.745286\n",
            "Epoch   18/20 Batch 1/3 Cost: 3.640306\n",
            "Epoch   18/20 Batch 2/3 Cost: 4.091382\n",
            "Epoch   18/20 Batch 3/3 Cost: 6.257708\n",
            "Epoch   19/20 Batch 1/3 Cost: 5.240420\n",
            "Epoch   19/20 Batch 2/3 Cost: 3.443764\n",
            "Epoch   19/20 Batch 3/3 Cost: 0.895925\n",
            "Epoch   20/20 Batch 1/3 Cost: 4.916792\n",
            "Epoch   20/20 Batch 2/3 Cost: 3.610375\n",
            "Epoch   20/20 Batch 3/3 Cost: 0.428304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 임의의 입력 [73, 80, 75]를 선언\n",
        "new_var =  torch.FloatTensor([[73, 80, 75]])\n",
        "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
        "pred_y = model(new_var)\n",
        "print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SxPQJ-teuvM",
        "outputId": "2b1f9729-a5f5-458f-9b56-d6168595bf7f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[153.9554]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    }
  ]
}